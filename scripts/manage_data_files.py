#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

å¤ã„æ¥½å¤©å•†å“ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’è¡Œã„ã¾ã™ã€‚
"""

import os
import argparse
from pathlib import Path
from datetime import datetime
from typing import List


def format_file_info(file_path: Path) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    stat = file_path.stat()
    size_mb = stat.st_size / 1024 / 1024
    mtime = datetime.fromtimestamp(stat.st_mtime)
    return f"{file_path.name:<45} | {size_mb:>8.1f}MB | {mtime.strftime('%Y-%m-%d %H:%M:%S')}"


def list_data_files():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º"""
    data_dir = Path('data')
    if not data_dir.exists():
        print("[ERROR] dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return
    
    rakuten_files = list(data_dir.glob('rakuten_uchiwai_products_*.json'))
    if not rakuten_files:
        print("ğŸ“ æ¥½å¤©å•†å“ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ä½œæˆæ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    rakuten_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    
    print(f"[LIST] æ¥½å¤©å•†å“ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ({len(rakuten_files)}å€‹)")
    print("=" * 80)
    print(f"{'ãƒ•ã‚¡ã‚¤ãƒ«å':<45} | {'ã‚µã‚¤ã‚º':<8} | ä½œæˆæ—¥æ™‚")
    print("-" * 80)
    
    total_size = 0
    for i, file_path in enumerate(rakuten_files):
        status = "æœ€æ–°" if i == 0 else f"{i+1}å€‹å‰"
        print(f"{status} {format_file_info(file_path)}")
        total_size += file_path.stat().st_size
    
    print("-" * 80)
    print(f"åˆè¨ˆ: {total_size / 1024 / 1024:.1f}MB")
    
    return rakuten_files


def cleanup_old_files(keep_count: int = 3, dry_run: bool = False, auto_confirm: bool = False):
    """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    print(f"[CLEANUP] å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (ä¿æŒæ•°: {keep_count})")
    
    files = list_data_files()
    if not files or len(files) <= keep_count:
        print(f"[OK] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦: {len(files) if files else 0}å€‹ <= {keep_count}å€‹")
        return
    
    files_to_delete = files[keep_count:]
    
    print(f"\n[DELETE] å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« ({len(files_to_delete)}å€‹):")
    total_delete_size = 0
    
    for file_path in files_to_delete:
        print(f"  [DEL] {format_file_info(file_path)}")
        total_delete_size += file_path.stat().st_size
    
    print(f"\nå‰Šé™¤äºˆå®šã‚µã‚¤ã‚º: {total_delete_size / 1024 / 1024:.1f}MB")
    
    if dry_run:
        print("[DRY-RUN] ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®å‰Šé™¤ã¯è¡Œã„ã¾ã›ã‚“")
        return
    
    # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆéå¯¾è©±å‹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if not auto_confirm:
        response = input(f"\næœ¬å½“ã«{len(files_to_delete)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã‹? [y/N]: ")
        if response.lower() != 'y':
            print("[CANCEL] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
    
    # å®Ÿéš›ã®å‰Šé™¤
    deleted_count = 0
    for file_path in files_to_delete:
        try:
            file_path.unlink()
            print(f"[OK] å‰Šé™¤: {file_path.name}")
            deleted_count += 1
        except Exception as e:
            print(f"[ERROR] å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {file_path.name} - {e}")
    
    print(f"\n[DONE] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_count}/{len(files_to_delete)}å€‹å‰Šé™¤")


def analyze_disk_usage():
    """ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡åˆ†æ"""
    data_dir = Path('data')
    if not data_dir.exists():
        return
    
    print("[DISK] ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡åˆ†æ")
    print("=" * 50)
    
    file_types = {
        'rakuten_products': 'rakuten_uchiwai_products_*.json',
        'genre_cache': 'genre_cache.json',
        'mapping_rules': 'genre_mapping_rules.json',
        'settings': 'meili_settings.json',
        'progress': 'fetch_progress.json'
    }
    
    total_size = 0
    for name, pattern in file_types.items():
        files = list(data_dir.glob(pattern))
        if files:
            size = sum(f.stat().st_size for f in files)
            total_size += size
            print(f"{name:<15}: {size / 1024 / 1024:>8.1f}MB ({len(files)}ãƒ•ã‚¡ã‚¤ãƒ«)")
        else:
            print(f"{name:<15}: {'0.0':>8}MB (0ãƒ•ã‚¡ã‚¤ãƒ«)")
    
    print("-" * 50)
    print(f"{'ç·ä½¿ç”¨é‡':<15}: {total_size / 1024 / 1024:>8.1f}MB")


def main():
    parser = argparse.ArgumentParser(
        description='ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
  python manage_data_files.py --list

  # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡åˆ†æ
  python manage_data_files.py --analyze

  # 5å€‹ã¾ã§ä¿æŒã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  python manage_data_files.py --cleanup --keep 5

  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå‰Šé™¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  python manage_data_files.py --cleanup --keep 5 --dry-run

  # è‡ªå‹•å®Ÿè¡Œï¼ˆç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—ï¼‰
  python manage_data_files.py --cleanup --keep 5 --auto-confirm
        """
    )
    
    parser.add_argument(
        '--list',
        action='store_true',
        help='ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º'
    )
    
    parser.add_argument(
        '--cleanup',
        action='store_true',
        help='å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—'
    )
    
    parser.add_argument(
        '--analyze',
        action='store_true',
        help='ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã‚’åˆ†æ'
    )
    
    parser.add_argument(
        '--keep',
        type=int,
        default=3,
        help='ä¿æŒã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='å‰Šé™¤ã›ãšã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿å®Ÿè¡Œ'
    )
    
    parser.add_argument(
        '--auto-confirm',
        action='store_true',
        help='å‰Šé™¤ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè‡ªå‹•å®Ÿè¡Œç”¨ï¼‰'
    )
    
    args = parser.parse_args()
    
    if not any([args.list, args.cleanup, args.analyze]):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸€è¦§è¡¨ç¤º
        args.list = True
    
    if args.list:
        list_data_files()
    
    if args.analyze:
        if args.list:
            print()
        analyze_disk_usage()
    
    if args.cleanup:
        if args.list or args.analyze:
            print()
        cleanup_old_files(args.keep, args.dry_run, args.auto_confirm)


if __name__ == '__main__':
    main()