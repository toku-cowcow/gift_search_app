"""
å•†å“ã®è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œã¨å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
1. åŸºæœ¬occasionã«è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªï¼ˆoccasionsé…åˆ—ï¼‰ã‚’è¿½åŠ 
2. å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰genre_groupã‚’æ¨å®š
3. Meilisearchã«å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

æ¥½å¤©APIå–å¾—æ™‚ã«åŸºæœ¬occasionã¯è¨­å®šæ¸ˆã¿:
- wedding_celebration: çµå©šç¥ã„
- birth_celebration: å‡ºç”£ç¥ã„
- new_home_celebration: æ–°ç¯‰ç¥ã„
- mothers_day: æ¯ã®æ—¥
- fathers_day: çˆ¶ã®æ—¥
- respect_for_aged_day: æ•¬è€ã®æ—¥

è¿½åŠ å‡¦ç†:
- occasionsé…åˆ—: å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è¤‡æ•°ç”¨é€”ã‚’åˆ¤å®š
- genre_group: å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡
"""

import os
import sys
import json
import time
from typing import List, Dict, Any, Set
from pathlib import Path

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦backendãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨å¯èƒ½ã«ã™ã‚‹
script_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.join(os.path.dirname(script_dir), 'backend')
sys.path.append(backend_dir)

from app.services.search_service_fixed import MeilisearchService


class MultiCategoryProcessor:
    """è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼"""
    
    def __init__(self):
        # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªæ¨å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.occasion_keywords = {
            'wedding_celebration': [
                'çµå©š', 'ã‚¦ã‚§ãƒ‡ã‚£ãƒ³ã‚°', 'ãƒ–ãƒ©ã‚¤ãƒ€ãƒ«', 'æ–°éƒ', 'æ–°å©¦', 'èŠ±å«', 'èŠ±å©¿',
                'ãƒãƒªãƒƒã‚¸', 'çµå©šå¼', 'æŠ«éœ²å®´', 'æŒ™å¼', 'çµå©šç¥ã„', 'ã‚¦ã‚¨ãƒ‡ã‚£ãƒ³ã‚°'
            ],
            'birth_celebration': [
                'å‡ºç”£', 'èµ¤ã¡ã‚ƒã‚“', 'ãƒ™ãƒ“ãƒ¼', 'æ–°ç”Ÿå…', 'èª•ç”Ÿ', 'ãƒãƒ¼ã‚¹',
                'ãƒã‚¿ãƒ‹ãƒ†ã‚£', 'å¦Šå¨ ', 'å‡ºç”£ç¥ã„', 'ãƒ™ã‚¤ãƒ“ãƒ¼', 'å­è‚²ã¦', 'è‚²å…'
            ],
            'new_home_celebration': [
                'æ–°ç¯‰', 'æ–°å±…', 'å¼•è¶Šã—', 'å¼•ã£è¶Šã—', 'ãƒã‚¤ãƒ›ãƒ¼ãƒ ', 'æ–°ç¯‰ç¥ã„',
                'å®¶å…·', 'ã‚¤ãƒ³ãƒ†ãƒªã‚¢', 'ä½å®…', 'æ–°ç¯‰å®Œæˆ', 'ãŠå¼•è¶Šã—', 'è»¢å±…'
            ],
            'mothers_day': [
                'æ¯ã®æ—¥', 'ãŠæ¯ã•ã‚“', 'ãƒãƒ', 'æ¯è¦ª', 'ãƒã‚¶ãƒ¼', 'mother',
                'æ„Ÿè¬', 'æ¯ã¸ã®', 'ãŠç–²ã‚Œã•ã¾', 'æ¯ã®', 'ã‚«ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³'
            ],
            'fathers_day': [
                'çˆ¶ã®æ—¥', 'ãŠçˆ¶ã•ã‚“', 'ãƒ‘ãƒ‘', 'çˆ¶è¦ª', 'ãƒ•ã‚¡ã‚¶ãƒ¼', 'father',
                'çˆ¶ã¸ã®', 'ãŠç–²ã‚Œæ§˜', 'ãƒ‘ãƒ‘ã•ã‚“', 'çˆ¶ã®', 'ãƒã‚¯ã‚¿ã‚¤'
            ],
            'respect_for_aged_day': [
                'æ•¬è€ã®æ—¥', 'ãŠã˜ã„ã¡ã‚ƒã‚“', 'ãŠã°ã‚ã¡ã‚ƒã‚“', 'ç¥–çˆ¶', 'ç¥–æ¯',
                'é•·å¯¿', 'é«˜é½¢è€…', 'ã‚·ãƒ«ãƒãƒ¼', 'æ•¬è€', 'ãŠã˜ã„ã•ã‚“', 'ãŠã°ã‚ã•ã‚“'
            ]
        }
        
        # ã‚¸ãƒ£ãƒ³ãƒ«æ¨å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.genre_keywords = {
            'food': [
                'é£Ÿå“', 'ã‚¹ã‚¤ãƒ¼ãƒ„', 'ãŠè“å­', 'ã‚°ãƒ«ãƒ¡', 'å’Œè“å­', 'æ´‹è“å­',
                'ã‚±ãƒ¼ã‚­', 'ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆ', 'ç±³', 'ãƒ‘ãƒ³', 'è‚‰', 'é­š', 'æœç‰©',
                'é‡èœ', 'èª¿å‘³æ–™', 'é†¤æ²¹', 'å‘³å™Œ', 'èœ‚èœœ', 'ãƒãƒ ', 'ã‚½ãƒ¼ã‚»ãƒ¼ã‚¸',
                'ä½ƒç…®', 'æ¼¬ç‰©', 'ä¹¾ç‰©', 'æµ·è‹”', 'æ˜†å¸ƒ', 'é°¹ç¯€', 'ã ã—',
                'ã‚«ã‚¹ãƒ†ãƒ©', 'ãƒã‚¦ãƒ ã‚¯ãƒ¼ãƒ˜ãƒ³', 'ã‚¯ãƒƒã‚­ãƒ¼', 'ã›ã‚“ã¹ã„', 'é¥…é ­'
            ],
            'drink': [
                'é£²æ–™', 'ãƒ‰ãƒªãƒ³ã‚¯', 'ã‚¸ãƒ¥ãƒ¼ã‚¹', 'ã‚³ãƒ¼ãƒ’ãƒ¼', 'ç´…èŒ¶', 'ç·‘èŒ¶',
                'ãŠèŒ¶', 'æ—¥æœ¬é…’', 'ãƒ¯ã‚¤ãƒ³', 'ãƒ“ãƒ¼ãƒ«', 'ç„¼é…', 'æ³¡ç››', 'æ¢…é…’',
                'ã‚¦ã‚¤ã‚¹ã‚­ãƒ¼', 'ãƒ–ãƒ©ãƒ³ãƒ‡ãƒ¼', 'é…’', 'ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«', 'æ¸…é…’',
                'æ°´', 'ãƒŸãƒãƒ©ãƒ«ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼', 'ã‚½ãƒ•ãƒˆãƒ‰ãƒªãƒ³ã‚¯'
            ],
            'home': [
                'ã‚¿ã‚ªãƒ«', 'ç”Ÿæ´»é›‘è²¨', 'æ—¥ç”¨å“', 'é£Ÿå™¨', 'çš¿', 'ã‚«ãƒƒãƒ—', 'ãƒã‚°',
                'ã‚°ãƒ©ã‚¹', 'ã‚³ãƒƒãƒ—', 'ç®¸', 'ã‚¹ãƒ—ãƒ¼ãƒ³', 'ãƒ•ã‚©ãƒ¼ã‚¯', 'ãƒŠã‚¤ãƒ•',
                'é‹', 'ãƒ•ãƒ©ã‚¤ãƒ‘ãƒ³', 'èª¿ç†å™¨å…·', 'ã‚­ãƒƒãƒãƒ³', 'æ´—å‰¤', 'çŸ³é¹¸',
                'ã‚·ãƒ£ãƒ³ãƒ—ãƒ¼', 'ãƒã‚¹', 'å¯å…·', 'ã‚·ãƒ¼ãƒ„', 'æ•', 'ã‚¯ãƒƒã‚·ãƒ§ãƒ³',
                'åç´', 'ã‚±ãƒ¼ã‚¹', 'ãƒœãƒƒã‚¯ã‚¹', 'å®¹å™¨', 'ãƒãƒƒã‚°', 'è²¡å¸ƒ'
            ],
            'catalog': [
                'ã‚«ã‚¿ãƒ­ã‚°', 'ã‚®ãƒ•ãƒˆã‚«ã‚¿ãƒ­ã‚°', 'ãƒãƒ§ã‚¤ã‚¹', 'ã‚»ãƒ¬ã‚¯ãƒˆ',
                'ã‚«ã‚¿ãƒ­ã‚°ã‚®ãƒ•ãƒˆ', 'é¸ã¹ã‚‹', 'ãƒã‚±ãƒƒãƒˆ', 'ã‚®ãƒ•ãƒˆåˆ¸',
                'å•†å“åˆ¸', 'ä½“é¨“', 'ã‚¨ã‚¹ãƒ†', 'ãƒªãƒ©ã‚¯ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³'
            ],
            'craft': [
                'å·¥èŠ¸', 'ä¼çµ±', 'æ‰‹ä½œã‚Š', 'è·äºº', 'é™¶å™¨', 'ç£å™¨', 'æ¼†å™¨',
                'æœ¨å·¥', 'ç«¹', 'å’Œç´™', 'æŸ“ç‰©', 'ç¹”ç‰©', 'åˆºç¹', 'é‡‘å±',
                'éŠ€', 'é‡‘', 'ä¼çµ±å·¥èŠ¸', 'æ°‘èŠ¸', 'å·¥èŠ¸å“', 'ä½œå®¶'
            ],
            'flower': [
                'èŠ±', 'ãƒ•ãƒ©ãƒ¯ãƒ¼', 'æ¤ç‰©', 'ãƒ—ãƒ©ãƒ³ãƒ„', 'è¦³è‘‰æ¤ç‰©', 'é‰¢æ¤ãˆ',
                'ã‚¬ãƒ¼ãƒ‡ãƒ‹ãƒ³ã‚°', 'åœ’èŠ¸', 'ãƒ–ãƒ¼ã‚±', 'ã‚¢ãƒ¬ãƒ³ã‚¸ãƒ¡ãƒ³ãƒˆ',
                'ãƒ—ãƒªã‚¶ãƒ¼ãƒ–ãƒ‰', 'ãƒ‰ãƒ©ã‚¤ãƒ•ãƒ©ãƒ¯ãƒ¼', 'èƒ¡è¶è˜­', 'ãƒãƒ©'
            ]
        }
    
    def detect_additional_occasions(self, title: str, description: str = "", current_occasion: str = "") -> Set[str]:
        """å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã‹ã‚‰è¿½åŠ ã®ç”¨é€”ã‚’æ¨å®š"""
        text = (title + " " + description).lower()
        occasions = set()
        
        # ç¾åœ¨ã®occasionã¯å¿…ãšå«ã‚ã‚‹
        if current_occasion:
            occasions.add(current_occasion)
        
        # è¿½åŠ ã®ç”¨é€”ã‚’æ¤œç´¢
        for occasion, keywords in self.occasion_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text:
                    occasions.add(occasion)
                    break
        
        return occasions
    
    def classify_genre(self, title: str, description: str = "") -> str:
        """å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æ¨å®š"""
        text = (title + " " + description).lower()
        genre_scores = {}
        
        for genre, keywords in self.genre_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword.lower() in text:
                    # ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã»ã©é«˜å¾—ç‚¹
                    score += len(keyword)
            genre_scores[genre] = score
        
        # æœ€é«˜å¾—ç‚¹ã®ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¿”ã™
        if genre_scores and max(genre_scores.values()) > 0:
            return max(genre_scores.items(), key=lambda x: x[1])[0]
        
        return "home"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç”Ÿæ´»é›‘è²¨ãƒ»æ—¥ç”¨å“
    
    def process_products(self, source_file: str) -> List[Dict[str, Any]]:
        """å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        print(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {source_file}")
        
        with open(source_file, 'r', encoding='utf-8') as f:
            products = json.load(f)
        
        print(f"ğŸ“Š å‡¦ç†å¯¾è±¡å•†å“æ•°: {len(products)}ä»¶")
        
        processed_products = []
        
        for i, product in enumerate(products):
            # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š
            current_occasion = product.get('occasion', '')
            description = product.get('description', '')
            
            occasions = self.detect_additional_occasions(
                product['title'],
                description,
                current_occasion
            )
            
            # ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æ¨å®š
            genre_group = self.classify_genre(product['title'], description)
            
            # å‡¦ç†æ¸ˆã¿å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            processed_product = product.copy()
            processed_product['occasions'] = list(occasions)
            processed_product['genre_group'] = genre_group
            
            # occasionsé…åˆ—ã«occasionãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯è¿½åŠ 
            if current_occasion and current_occasion not in processed_product['occasions']:
                processed_product['occasions'].append(current_occasion)
            
            processed_products.append(processed_product)
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % 500 == 0:
                print(f"  å‡¦ç†æ¸ˆã¿: {i + 1:,}/{len(products):,}ä»¶")
        
        print("âœ… å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†")
        return processed_products
    
    def reindex_to_meilisearch(self, products: List[Dict[str, Any]], batch_size: int = 100):
        """Meilisearchã«å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"""
        print("ğŸ“¤ Meilisearchã«å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸­...")
        
        service = MeilisearchService()
        
        # æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚¯ãƒªã‚¢
        print("ğŸ—‘ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ä¸­...")
        service.index.delete_all_documents()
        time.sleep(2)  # ã‚¯ãƒªã‚¢å®Œäº†ã‚’å¾…æ©Ÿ
        
        # ãƒãƒƒãƒã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        total_batches = (len(products) + batch_size - 1) // batch_size
        
        for i in range(0, len(products), batch_size):
            batch = products[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            
            print(f"  ãƒãƒƒãƒ {batch_num}/{total_batches}: {len(batch)}ä»¶ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸­...")
            
            # Meilisearchã«é€ä¿¡
            task = service.index.add_documents(batch)
            
            # ãƒãƒƒãƒé–“ã§å°‘ã—å¾…æ©Ÿ
            time.sleep(0.1)
        
        print("âœ… å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†")
        
        # çµ±è¨ˆã‚’è¡¨ç¤º
        self.print_reindex_stats(products)
    
    def print_reindex_stats(self, products: List[Dict[str, Any]]):
        """å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆã‚’è¡¨ç¤º"""
        print("\n=== ğŸ“Š å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆ ===")
        
        # ç”¨é€”åˆ¥çµ±è¨ˆ
        occasion_stats = {}
        for product in products:
            primary_occasion = product.get('occasion', 'unknown')
            occasion_stats[primary_occasion] = occasion_stats.get(primary_occasion, 0) + 1
        
        print("\nğŸ¯ åŸºæœ¬ç”¨é€”åˆ¥å•†å“æ•°:")
        occasion_names = {
            'wedding_celebration': 'çµå©šç¥ã„',
            'birth_celebration': 'å‡ºç”£ç¥ã„',
            'new_home_celebration': 'æ–°ç¯‰ç¥ã„',
            'mothers_day': 'æ¯ã®æ—¥',
            'fathers_day': 'çˆ¶ã®æ—¥',
            'respect_for_aged_day': 'æ•¬è€ã®æ—¥'
        }
        
        for occasion, count in occasion_stats.items():
            name = occasion_names.get(occasion, occasion)
            print(f"  {name}: {count}ä»¶")
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµ±è¨ˆ
        genre_stats = {}
        for product in products:
            genre = product.get('genre_group', 'unknown')
            genre_stats[genre] = genre_stats.get(genre, 0) + 1
        
        print("\nğŸ“¦ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥å•†å“æ•°:")
        genre_names = {
            'food': 'é£Ÿå“ãƒ»ã‚¹ã‚¤ãƒ¼ãƒ„',
            'drink': 'é£²æ–™',
            'home': 'ç”Ÿæ´»é›‘è²¨ãƒ»æ—¥ç”¨å“',
            'catalog': 'ã‚«ã‚¿ãƒ­ã‚°ã‚®ãƒ•ãƒˆç­‰',
            'craft': 'å·¥èŠ¸ãƒ»ä¼çµ±é›‘è²¨',
            'flower': 'èŠ±ãƒ»æ¤ç‰©'
        }
        
        for genre, count in genre_stats.items():
            name = genre_names.get(genre, genre)
            print(f"  {name}: {count}ä»¶")
        
        # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
        multi_category_count = 0
        for product in products:
            occasions = product.get('occasions', [])
            if len(occasions) > 1:
                multi_category_count += 1
        
        print(f"\nğŸ”„ è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œå•†å“: {multi_category_count}ä»¶")
        
        print(f"\nğŸ“ˆ ç·å•†å“æ•°: {len(products)}ä»¶")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”„ HAREGift è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œ & å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    print("=" * 60)
    
    # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    script_dir = os.path.dirname(os.path.abspath(__file__))
    rakuten_dir = os.path.join(script_dir, 'data', 'sources', 'rakuten')
    
    if not os.path.exists(rakuten_dir):
        print(f"âŒ æ¥½å¤©ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {rakuten_dir}")
        return
    
    # æœ€æ–°ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆHAREGiftãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆï¼‰
    json_files = [f for f in os.listdir(rakuten_dir) if f.endswith('.json')]
    if not json_files:
        print("âŒ æ¥½å¤©ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # HAREGiftãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆã—ã¦é¸æŠ
    haregift_files = [f for f in json_files if 'haregift' in f]
    if haregift_files:
        latest_file = sorted(haregift_files)[-1]
    else:
        latest_file = sorted(json_files)[-1]
    source_path = os.path.join(rakuten_dir, latest_file)
    
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
    
    # å‡¦ç†é–‹å§‹ç¢ºèª
    print(f"\nä»¥ä¸‹ã®å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™:")
    print(f"1. ğŸ“„ å•†å“ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
    print(f"2. ğŸ”„ è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªå¯¾å¿œå‡¦ç†")
    print(f"3. ğŸ·ï¸ ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡")
    print(f"4. ğŸ“¤ Meilisearchå†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    
    response = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
    if response.lower() != 'y':
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return
    
    # å‡¦ç†å®Ÿè¡Œ
    processor = MultiCategoryProcessor()
    
    try:
        # 1. å•†å“ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        processed_products = processor.process_products(source_path)
        
        # 2. Meilisearchå†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        processor.reindex_to_meilisearch(processed_products)
        
        print("\nğŸ‰ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
    except Exception as e:
        print(f"\nğŸ’¥ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()