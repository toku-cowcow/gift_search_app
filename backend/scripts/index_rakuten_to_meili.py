#!/usr/bin/env python3
"""
æ¥½å¤©å•†å“JSONã‚’Meilisearchã«æŠ•å…¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import json
import html
import re
from datetime import datetime
from typing import Dict, List, Any
import argparse
import requests
import os

class RakutenToMeilisearchIndexer:
    def __init__(self, meili_url: str = "http://localhost:7700", master_key: str = "masterKey"):
        self.meili_url = meili_url
        self.master_key = master_key
        self.headers = {
            "Authorization": f"Bearer {master_key}",
            "Content-Type": "application/json"
        }
    
    def setup_index_settings(self, index_name: str):
        """Meilisearchã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã‚’é©ç”¨"""
        settings = {
            "filterableAttributes": ["occasion", "source", "price", "review_count", "review_average"],
            "sortableAttributes": ["price", "updated_at", "review_count", "review_average"],
            "searchableAttributes": ["title", "merchant", "description"]
        }
        
        response = requests.patch(
            f"{self.meili_url}/indexes/{index_name}/settings",
            headers=self.headers,
            json=settings
        )
        
        if response.status_code == 202:
            print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ: {index_name}")
            return response.json()
        else:
            print(f"âŒ è¨­å®šé©ç”¨ã«å¤±æ•—: {response.status_code} - {response.text}")
            return None
    
    def normalize_rakuten_item(self, item: Dict) -> Dict[str, Any]:
        """æ¥½å¤©å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’å†…éƒ¨ã‚¹ã‚­ãƒ¼ãƒã«æ­£è¦åŒ–"""
        # IDã®ç”Ÿæˆï¼ˆæ—¢å­˜ã®IDãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ã‚³ãƒ­ãƒ³ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«å¤‰æ›ï¼‰
        if 'id' in item and item['id']:
            item_id = item['id'].replace(':', '_')
        else:
            item_code = item.get('itemCode', 'unknown').replace(':', '_')
            item_id = f"rakuten_{item_code}"
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã®HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—è§£é™¤
        title = html.unescape(item.get('title', item.get('itemName', '')))
        description = html.unescape(item.get('description', item.get('itemCaption', '')))
        merchant = html.unescape(item.get('merchant', item.get('shopName', '')))
        
        # ç”»åƒURLå–å¾—
        image_url = item.get('image_url', '')
        if not image_url:
            image_urls = item.get('mediumImageUrls', [])
            image_url = image_urls[0].get('imageUrl', '') if image_urls else ''
        
        # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLï¼ˆæ—¢å­˜ã‹ã€ãªã‘ã‚Œã°itemUrlï¼‰
        affiliate_url = item.get('affiliate_url', item.get('affiliateUrl', item.get('itemUrl', '')))
        
        # ä¾¡æ ¼ï¼ˆæ•°å€¤å¤‰æ›ï¼‰
        price = int(item.get('price', item.get('itemPrice', 0)))
        
        # occasionåˆ¤å®šï¼ˆç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰
        occasion = self._determine_occasion(title, description)
        
        # ç¾åœ¨æ™‚åˆ»
        updated_at = datetime.now().isoformat()
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        review_count = int(item.get('review_count', 0))
        review_average = float(item.get('review_average', 0.0))
        
        return {
            "id": item_id,
            "title": title,
            "price": price,
            "image_url": image_url,
            "merchant": merchant,
            "affiliate_url": affiliate_url,
            "updated_at": updated_at,
            "source": "Rakuten",
            "occasion": occasion,
            "description": description,
            "review_count": review_count,
            "review_average": review_average
        }
    
    def _determine_occasion(self, title: str, description: str) -> str:
        """ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§occasionã‚’åˆ¤å®š"""
        text = f"{title} {description}".lower()
        
        # é¦™å…¸è¿”ã—ãƒ»æ³•è¦é–¢é€£
        if re.search(r'é¦™å…¸è¿”ã—|æ³•è¦|ä»äº‹|ãŠä¾›ãˆ|å¼”äº‹|å››åä¹æ—¥|ä¸€å‘¨å¿Œ|ä¸‰å›å¿Œ', text):
            return "funeral_return"
        
        # çµå©šé–¢é€£
        if re.search(r'çµå©š|ãƒ–ãƒ©ã‚¤ãƒ€ãƒ«|ã‚¦ã‚§ãƒ‡ã‚£ãƒ³ã‚°|çµå©šç¥ã„|çµå©šå†…ç¥ã„', text):
            return "wedding_return"
        
        # å‡ºç”£é–¢é€£
        if re.search(r'å‡ºç”£|ãƒ™ãƒ“ãƒ¼|å‘½å|å‡ºç”£ç¥ã„|å‡ºç”£å†…ç¥ã„|èµ¤ã¡ã‚ƒã‚“', text):
            return "baby_return"
        
        # æ–°ç¯‰ãƒ»å¼•è¶Šé–¢é€£
        if re.search(r'æ–°ç¯‰|å¼•è¶Š|å¼•ã£è¶Šã—|æ–°å±…|æ–°ç¯‰ç¥ã„', text):
            return "new_home"
        
        # å¿«æ°—ãƒ»ãŠè¦‹èˆã„é–¢é€£
        if re.search(r'å¿«æ°—|ãŠè¦‹èˆã„|å›å¾©|å¿«æ°—ç¥ã„|å¿«æ°—å†…ç¥ã„', text):
            return "recovery"
        
        # ã©ã‚Œã«ã‚‚è©²å½“ã—ãªã„å ´åˆã¯ç©ºæ–‡å­—
        return ""
    
    def index_products(self, json_file_path: str, index_name: str, chunk_size: int = 1000):
        """æ¥½å¤©å•†å“JSONã‚’Meilisearchã«æŠ•å…¥"""
        print(f"ğŸ“‚ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {json_file_path}")
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            rakuten_products = json.load(f)
        
        print(f"ğŸ“Š {len(rakuten_products)} ä»¶ã®å•†å“ã‚’å‡¦ç†ã—ã¾ã™")
        
        # æ­£è¦åŒ–å‡¦ç†
        normalized_products = []
        for item in rakuten_products:
            try:
                normalized_item = self.normalize_rakuten_item(item)
                normalized_products.append(normalized_item)
            except Exception as e:
                print(f"âš ï¸ å•†å“å‡¦ç†ã‚¨ãƒ©ãƒ¼: {item.get('itemCode', 'unknown')} - {e}")
                continue
        
        print(f"âœ… {len(normalized_products)} ä»¶ã®å•†å“ã‚’æ­£è¦åŒ–ã—ã¾ã—ãŸ")
        
        # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦æŠ•å…¥
        total_indexed = 0
        for i in range(0, len(normalized_products), chunk_size):
            chunk = normalized_products[i:i + chunk_size]
            
            response = requests.post(
                f"{self.meili_url}/indexes/{index_name}/documents",
                headers=self.headers,
                json=chunk
            )
            
            if response.status_code == 202:
                total_indexed += len(chunk)
                print(f"ğŸ“¤ {len(chunk)} ä»¶æŠ•å…¥å®Œäº† (ç´¯è¨ˆ: {total_indexed}/{len(normalized_products)})")
            else:
                print(f"âŒ æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                break
        
        print(f"ğŸ‰ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†: {total_indexed} ä»¶")
        return total_indexed

def main():
    parser = argparse.ArgumentParser(description="æ¥½å¤©å•†å“JSONã‚’Meilisearchã«æŠ•å…¥")
    parser.add_argument("--json", required=True, help="æ¥½å¤©å•†å“JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--index", default="items", help="Meilisearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å")
    parser.add_argument("--chunk", type=int, default=1000, help="æŠ•å…¥ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º")
    parser.add_argument("--meili-url", default="http://localhost:7700", help="Meilisearchã‚µãƒ¼ãƒãƒ¼URL")
    parser.add_argument("--master-key", default="masterKey", help="Meilisearchãƒã‚¹ã‚¿ãƒ¼ã‚­ãƒ¼")
    
    args = parser.parse_args()
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®å–å¾—ã‚‚å¯èƒ½
    meili_url = os.getenv("MEILI_URL", args.meili_url)
    master_key = os.getenv("MEILI_MASTER_KEY", args.master_key)
    
    indexer = RakutenToMeilisearchIndexer(meili_url, master_key)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã‚’é©ç”¨
    print("ğŸ”§ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã‚’é©ç”¨ä¸­...")
    indexer.setup_index_settings(args.index)
    
    # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥
    print("ğŸ“¥ å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ä¸­...")
    indexer.index_products(args.json, args.index, args.chunk)

if __name__ == "__main__":
    main()

# å®Ÿè¡Œæ‰‹é †ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã®ç’°å¢ƒã§å®Ÿè¡Œã™ã‚‹æƒ³å®šï¼‰
"""
# åŸºæœ¬å®Ÿè¡Œ
python backend/scripts/index_rakuten_to_meili.py \
  --json frontend/public/data/rakuten_uchiwai_products_20251030_233859.json \
  --index items \
  --chunk 1000

# ç’°å¢ƒå¤‰æ•°ä½¿ç”¨
export MEILI_URL=http://localhost:7700
export MEILI_MASTER_KEY=your_master_key
python backend/scripts/index_rakuten_to_meili.py \
  --json frontend/public/data/rakuten_uchiwai_products_20251030_233859.json \
  --index items
"""