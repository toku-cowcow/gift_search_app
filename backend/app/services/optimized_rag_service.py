"""
Phase 3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç‰ˆ LangChain RAGã‚µãƒ¼ãƒ“ã‚¹

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²:
- Phase 2ã®æ©Ÿèƒ½ã‚’ä¿æŒã—ã¤ã¤ã€å¿œç­”æ™‚é–“ã‚’å¤§å¹…çŸ­ç¸®
- ä¸¦åˆ—å‡¦ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®å®Ÿè£…
- 3-5ç§’ä»¥å†…ã®å¿œç­”æ™‚é–“ã‚’ç›®æŒ‡ã™
"""

import asyncio
import json
import logging
import hashlib
import time
import os
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

# LangChain imports
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS

from ..core.config import settings
from ..schemas import GiftItem, SearchParams
from .search_service_fixed import MeilisearchService
from .hybrid_search_engine import HybridSearchEngine

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)


# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)


class VectorStoreManager:
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ç®¡ç†"""
    
    _instance = None
    _vector_store = None
    _lock = Lock()
    
    @classmethod
    def get_vector_store(cls) -> Optional[FAISS]:
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls()
                    cls._instance._load_vector_store()
        
        return cls._vector_store
    
    def _load_vector_store(self):
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not settings.is_ai_enabled():
                logger.warning("OpenAI APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¯èª­ã¿è¾¼ã¾ã‚Œã¾ã›ã‚“")
                VectorStoreManager._vector_store = None
                return
                
            vector_store_path = os.path.join(
                os.path.dirname(__file__), 
                "../../../data/vector_store"
            )
            
            if os.path.exists(vector_store_path):
                embeddings = OpenAIEmbeddings(api_key=settings.openai_api_key)
                VectorStoreManager._vector_store = FAISS.load_local(
                    vector_store_path, 
                    embeddings,
                    allow_dangerous_deserialization=True
                )
                logger.info("âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿å®Œäº†ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰")
            else:
                logger.warning(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vector_store_path}")
                VectorStoreManager._vector_store = None
                
        except Exception as e:
            logger.error(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            VectorStoreManager._vector_store = None
    
    @classmethod
    def cleanup(cls):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        with cls._lock:
            cls._vector_store = None
            cls._instance = None


from functools import lru_cache
from threading import Lock

class PerformanceOptimizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§1ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿ç”Ÿæˆ"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.cache = {}
        self.cache_ttl = timedelta(minutes=30)  # 30åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.max_cache_size = 1000  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
        self._executor = None
        self._lock = Lock()
        self._initialized = True
    
    def get_executor(self) -> ThreadPoolExecutor:
        """ThreadPoolExecutorã‚’é…å»¶åˆæœŸåŒ–ã§å–å¾—"""
        if self._executor is None:
            with self._lock:
                if self._executor is None:
                    self._executor = ThreadPoolExecutor(max_workers=4)
        return self._executor
    
    def get_cache_key(self, data: Any) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
        return hashlib.md5(str(data).encode()).hexdigest()
    
    def get_cached(self, key: str) -> Optional[Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        if key in self.cache:
            value, timestamp = self.cache[key]
            if datetime.now() - timestamp < self.cache_ttl:
                return value
            else:
                del self.cache[key]
        return None
    
    def set_cached(self, key: str, value: Any):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºåˆ¶é™ä»˜ãï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(self.cache) >= self.max_cache_size:
            # å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆLRUçš„ã«ï¼‰
            oldest_key = min(self.cache.keys(), 
                           key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]
            
        self.cache[key] = (value, datetime.now())
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self.cache.clear()
        
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self._executor is not None:
            self._executor.shutdown(wait=True)
            self._executor = None
        self.clear_cache()
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.cleanup()


class OptimizedUserIntentExtractor:
    """æœ€é©åŒ–ç‰ˆæ„å›³æŠ½å‡ºå™¨"""
    
    def __init__(self, llm: ChatOpenAI, optimizer: PerformanceOptimizer):
        self.llm = llm
        self.optimizer = optimizer
        self._setup_optimized_prompt()
    
    def _setup_optimized_prompt(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸç°¡æ½”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""            
        self.intent_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰æ„å›³ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚

ä¾‹ï¼š
å…¥åŠ›: "ç”¨é€”: çµå©šå†…ç¥ã„ã€ç›¸æ‰‹: ä¸Šå¸ãƒ»ç›®ä¸Šã®æ–¹ã€äºˆç®—: 3000å††ã€œ5000å††"
å‡ºåŠ›: {"occasion":"wedding_return","target_relationship":"boss","budget_min":3000,"budget_max":5000,"keywords":["ä¸Šå“","å†…ç¥ã„"]}

äºˆç®—ã®æŠ½å‡ºè¦å‰‡:
- "3000å††ã€œ5000å††" â†’ budget_min:3000, budget_max:5000
- "5000å††ãã‚‰ã„" â†’ budget_min:4000, budget_max:6000  
- "1ä¸‡å††ä»¥ä¸‹" â†’ budget_min:null, budget_max:10000
- "äºˆç®—ãªã—" â†’ budget_min:null, budget_max:null

occasion: wedding_return(çµå©šå†…ç¥ã„), baby_return(å‡ºç”£å†…ç¥ã„), funeral_return(é¦™å…¸è¿”ã—), celebration_return(ãŠç¥ã„è¿”ã—), business(ãƒ“ã‚¸ãƒã‚¹é–¢ä¿‚), other(ãã®ä»–), unknown
target_relationship: boss(ä¸Šå¸ãƒ»ç›®ä¸Šã®æ–¹), colleague(åŒåƒš), friend(å‹äºº), family(è¦ªæ—), client(å–å¼•å…ˆ), other(ãã®ä»–), unknown  
budget_min/max: æ•°å€¤ã¾ãŸã¯null
keywords: é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é…åˆ—

JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„å‰æ›¸ãã¯ä¸è¦ã§ã™ã€‚
"""),
            ("user", "{user_input}")
        ])
    
    async def extract_intent(self, user_input: str) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé«˜é€Ÿæ„å›³æŠ½å‡º
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèªï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
        # cache_key = self.optimizer.get_cache_key(f"intent_{user_input}")
        # cached_result = self.optimizer.get_cached(cache_key)
        
        # if cached_result:
        #     logger.info(f"æ„å›³æŠ½å‡ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {user_input[:50]}...")
        #     return cached_result
        
        try:
            start_time = time.time()
            
            logger.info(f"ğŸ” æ„å›³æŠ½å‡ºé–‹å§‹: {user_input}")
            
            response = await self.llm.ainvoke(
                self.intent_prompt.format_messages(user_input=user_input)
            )
            
            # æ”¹å–„ã•ã‚ŒãŸJSONè§£æ
            content = response.content.strip()
            logger.info(f"ğŸ¤– LLMç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}")
            
            # JSONãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼ã‚’é™¤å»
            if content.startswith('```'):
                content = content.strip('`')
                if content.startswith('json\n'):
                    content = content[5:]  # "json\n"ã‚’å‰Šé™¤
                elif content.startswith('json'):
                    content = content[4:]  # "json"ã‚’å‰Šé™¤
                content = content.strip()
            
            # JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»ï¼ˆæœ€åˆã®{ã‹ã‚‰æœ€å¾Œã®}ã¾ã§æŠ½å‡ºï¼‰
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            if start_idx >= 0 and end_idx > start_idx:
                content = content[start_idx:end_idx]
            
            logger.info(f"ğŸ”§ å‡¦ç†å¾ŒJSON: {content}")
            
            # Pythonã£ã½ã„è¨˜æ³•ã‚’JSONå½¢å¼ã«å¤‰æ›
            content = content.replace("'", '"')  # å˜ä¸€å¼•ç”¨ç¬¦ã‚’äºŒé‡å¼•ç”¨ç¬¦ã«
            content = content.replace('None', 'null')  # Noneã‚’nullã«
            content = content.replace('True', 'true')  # Trueã‚’trueã«
            content = content.replace('False', 'false')  # Falseã‚’falseã«
            
            intent = json.loads(content)
            logger.info(f"âœ… ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿æ„å›³: {intent}")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è£œå®Œ
            intent = self._normalize_intent(intent)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
            # self.optimizer.set_cached(cache_key, intent)
            
            elapsed = time.time() - start_time
            logger.info(f"æ„å›³æŠ½å‡ºå®Œäº†: {elapsed:.2f}s, {intent}")
            
            return intent
            
        except json.JSONDecodeError as e:
            logger.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            fallback_intent = self._extract_intent_fallback(user_input)
            return fallback_intent
            
        except ConnectionError as e:
            logger.error(f"LLMæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            fallback_intent = self._extract_intent_fallback(user_input)
            return fallback_intent
            
        except ValueError as e:
            logger.warning(f"æ„å›³ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            fallback_intent = self._extract_intent_fallback(user_input)
            return fallback_intent
            
        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ ({type(e).__name__}): {str(e)}")
            import traceback
            logger.error(f"ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
            
            # ç°¡æ˜“çš„ãªæ„å›³æŠ½å‡ºãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            fallback_intent = self._extract_intent_fallback(user_input)
            logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ„å›³æŠ½å‡ºçµæœ: {fallback_intent}")
            return fallback_intent
    
    def _normalize_intent(self, intent: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å›³ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        
        # æ—¥æœ¬èªâ†’è‹±èªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆMeilisearchãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®å€¤ã«åˆã‚ã›ã¦ä¿®æ­£ï¼‰
        occasion_mapping = {
            "çµå©šå†…ç¥ã„": "wedding_return",
            "çµå©šç¥ã„": "wedding",
            "å‡ºç”£å†…ç¥ã„": "baby_return",  # birth_return -> baby_return ã«ä¿®æ­£
            "å‡ºç”£ç¥ã„": "baby_return",    # å‡ºç”£ç¥ã„ã‚‚åŒã˜ãbaby_returnã«ãƒãƒƒãƒ—
            "èª•ç”Ÿæ—¥": "birthday",
            "æ¯ã®æ—¥": "mothers_day",
            "çˆ¶ã®æ—¥": "fathers_day",
            "æ•¬è€ã®æ—¥": "respect_for_aged_day",
            "ã‚¯ãƒªã‚¹ãƒã‚¹": "christmas",
            "ãŠæ­³æš®": "oseibo",
            "ãŠä¸­å…ƒ": "ochugen",
            "æ–°ç¯‰ç¥ã„": "new_house",
            "å¼•è¶Šã—ç¥ã„": "moving",
            "å’æ¥­ç¥ã„": "graduation",
            "å…¥å­¦ç¥ã„": "entrance",
            "æ˜‡é€²ç¥ã„": "promotion",
            "é€€è·ç¥ã„": "retirement"
        }
        
        relationship_mapping = {
            "ä¸Šå¸ãƒ»ç›®ä¸Šã®æ–¹": "boss",
            "å‹äºº": "friend",
            "å®¶æ—": "family",
            "æ‹äºº": "lover",
            "åŒåƒš": "colleague",
            "éƒ¨ä¸‹": "subordinate",
            "è¦ªæˆš": "relative",
            "çŸ¥äºº": "acquaintance"
        }
        
        # occasionã‚’æ­£è¦åŒ–
        occasion_raw = intent.get("occasion", "unknown")
        occasion_normalized = occasion_mapping.get(occasion_raw, occasion_raw)
        
        # relationshipã‚’æ­£è¦åŒ–
        relationship_raw = intent.get("relationship", intent.get("target_relationship", "unknown"))
        relationship_normalized = relationship_mapping.get(relationship_raw, relationship_raw)
        
        # äºˆç®—ã‚’æ•°å€¤ã«å¤‰æ›
        budget_min = intent.get("budget_min")
        budget_max = intent.get("budget_max")
        
        try:
            if budget_min and isinstance(budget_min, str):
                budget_min = int(budget_min)
        except (ValueError, TypeError):
            budget_min = None
            
        try:
            if budget_max and isinstance(budget_max, str):
                budget_max = int(budget_max)
        except (ValueError, TypeError):
            budget_max = None
        
        return {
            "occasion": occasion_normalized,
            "target_relationship": relationship_normalized,
            "budget_min": budget_min,
            "budget_max": budget_max,
            "keywords": intent.get("keywords", []) if isinstance(intent.get("keywords"), list) else [],
            "gender": intent.get("gender", "unknown"),
            "urgency": intent.get("urgency", "normal")
        }
    
    def _get_default_intent(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ„å›³ï¼ˆæœ€å°é™ï¼‰"""
        return {
            "occasion": "unknown",
            "target_relationship": "unknown",
            "budget_min": None,
            "budget_max": None,
            "keywords": [],
            "gender": "unknown",
            "urgency": "normal"
        }
    
    def _extract_intent_fallback(self, user_input: str) -> Dict[str, Any]:
        """ç°¡æ˜“çš„ãªæ„å›³æŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ï¼‰"""
        import re
        
        intent = self._get_default_intent()
        
        # ç”¨é€”ã®æŠ½å‡º
        if "çµå©šå†…ç¥ã„" in user_input:
            intent["occasion"] = "wedding_return"
        elif "å‡ºç”£å†…ç¥ã„" in user_input:
            intent["occasion"] = "baby_return"
        elif "é¦™å…¸è¿”ã—" in user_input:
            intent["occasion"] = "funeral_return"
        elif "ãŠç¥ã„è¿”ã—" in user_input:
            intent["occasion"] = "celebration_return"
        
        # ç›¸æ‰‹ã®æŠ½å‡º
        if "ä¸Šå¸" in user_input or "ç›®ä¸Š" in user_input:
            intent["target_relationship"] = "boss"
        elif "åŒåƒš" in user_input:
            intent["target_relationship"] = "colleague"
        elif "å‹äºº" in user_input:
            intent["target_relationship"] = "friend"
        elif "è¦ªæ—" in user_input or "å®¶æ—" in user_input:
            intent["target_relationship"] = "family"
        
        # äºˆç®—ã®æŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ï¼‰
        budget_patterns = [
            r"(\d+)å††?ã€œ(\d+)å††?",  # 3000å††ã€œ5000å††
            r"(\d+)ã€œ(\d+)å††?",     # 3000ã€œ5000å††
            r"äºˆç®—:?\s*(\d+)å††?ã€œ(\d+)å††?",  # äºˆç®—: 3000å††ã€œ5000å††
            r"(\d+)å††?\s*ã‹ã‚‰\s*(\d+)å††?",  # 3000å††ã‹ã‚‰5000å††
            r"(\d+)\s*-\s*(\d+)å††?",       # 3000-5000å††
        ]
        
        logger.info(f"ğŸ” äºˆç®—æŠ½å‡ºå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ: '{user_input}'")
        
        for i, pattern in enumerate(budget_patterns):
            match = re.search(pattern, user_input)
            logger.info(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1} '{pattern}': {'ãƒãƒƒãƒ' if match else 'ãªã—'}")
            if match:
                budget_min = int(match.group(1))
                budget_max = int(match.group(2))
                intent["budget_min"] = budget_min
                intent["budget_max"] = budget_max
                logger.info(f"âœ… äºˆç®—æŠ½å‡ºæˆåŠŸ: {budget_min}å††ã€œ{budget_max}å††")
                break
        
        if intent["budget_min"] is None:
            logger.warning("âŒ äºˆç®—æŠ½å‡ºå¤±æ•—")
        
        logger.info(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ„å›³æŠ½å‡º: {intent}")
        return intent
    
    async def get_fast_recommendation_with_intent(
        self,
        user_input: str,
        user_intent: Dict[str, Any],
        chat_history: List[Dict[str, str]] = None,
        limit: int = 3
    ) -> Dict[str, Any]:
        """
        Phase 3: æ§‹é€ åŒ–ã•ã‚ŒãŸæ„å›³ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸé«˜é€Ÿæ¨è–¦
        
        ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸæ„å›³ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€
        æ„å›³æŠ½å‡ºã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥æ¤œç´¢ãƒ»æ¨è–¦ã‚’å®Ÿè¡Œ
        """
        start_time = datetime.now()
        processing_steps = []
        
        try:
            logger.info(f"Phase 3: æ§‹é€ åŒ–æ„å›³ã§ã®é«˜é€Ÿæ¨è–¦é–‹å§‹")
            logger.info(f"ğŸ“ å—ä¿¡ã—ãŸæ„å›³ãƒ‡ãƒ¼ã‚¿: {user_intent}")
            
            # Step 1: æ„å›³ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
            normalized_intent = self._normalize_intent(user_intent)
            processing_steps.append(f"æ§‹é€ åŒ–æ„å›³ãƒ‡ãƒ¼ã‚¿å—ä¿¡ãƒ»æ­£è¦åŒ–å®Œäº†")
            
            # Step 2: æœ€é©åŒ–ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
            search_start = time.time()
            hybrid_results, search_metadata = await self._fast_hybrid_search(
                query=user_input,
                user_intent=normalized_intent,
                limit=limit * 2  # ã‚ˆã‚Šå¤šãã®å€™è£œã‚’å–å¾—
            )
            search_time = time.time() - search_start
            processing_steps.append(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: {search_time:.2f}s")
            
            # Step 3: äºˆç®—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å¼·åˆ¶é©ç”¨
            if normalized_intent.get('budget_min') or normalized_intent.get('budget_max'):
                hybrid_results = self._apply_budget_filter(hybrid_results, normalized_intent)
                processing_steps.append(f"äºˆç®—ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {len(hybrid_results)}ä»¶")
            
            # Step 4: ä¸Šä½Nä»¶ã‚’é¸æŠ
            final_recommendations = hybrid_results[:limit]
            
            # Step 5: AIå¿œç­”ç”Ÿæˆ
            response_start = time.time()
            ai_response = await self._generate_fast_response(
                user_input, normalized_intent, final_recommendations
            )
            response_time = time.time() - response_start
            processing_steps.append(f"AIå¿œç­”ç”Ÿæˆ: {response_time:.2f}s")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬
            total_time = datetime.now() - start_time
            total_time_ms = total_time.total_seconds() * 1000
            
            logger.info(f"âœ… æ§‹é€ åŒ–æ„å›³æ¨è–¦å®Œäº†: {total_time_ms:.0f}ms")
            
            return {
                "recommendations": final_recommendations,
                "ai_response": ai_response,
                "intent_analysis": normalized_intent,
                "search_metadata": search_metadata,
                "processing_steps": processing_steps,
                "performance": {
                    "total_time_ms": total_time_ms,
                    "search_time_ms": search_time * 1000,
                    "response_time_ms": response_time * 1000,
                    "total_endpoint_time_ms": total_time_ms,
                    "optimization": "structured_intent"
                }
            }
            
        except Exception as e:
            logger.error(f"æ§‹é€ åŒ–æ„å›³æ¨è–¦ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return await self.get_fast_recommendation(user_input, chat_history, limit)


class OptimizedLangChainRAGService:
    """Phase 3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç‰ˆRAGã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        logger.info("Phase 3 æœ€é©åŒ–RAGã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–é–‹å§‹")
        
        # APIè¨­å®šã®æ¤œè¨¼
        api_validation = settings.validate_api_keys()
        logger.info(f"APIåˆ©ç”¨çŠ¶æ³: {api_validation}")
        
        if not settings.is_ai_enabled():
            logger.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIæ©Ÿèƒ½ã¯åˆ¶é™ã•ã‚Œã¾ã™ã€‚")
        
        self.meilisearch_service = MeilisearchService()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.optimizer = PerformanceOptimizer()
        
        # æœ€é©åŒ–ã•ã‚ŒãŸLLMè¨­å®šï¼ˆAPIã‚­ãƒ¼ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        if settings.is_ai_enabled():
            self.llm = ChatOpenAI(
                model_name=settings.openai_model,
                temperature=0.1,  # ä½æ¸©åº¦ã§é«˜é€ŸåŒ–
                max_tokens=800,   # ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™
                api_key=settings.openai_api_key
            )
            
            self.embeddings = OpenAIEmbeddings(api_key=settings.openai_api_key)
        else:
            self.llm = None
            self.embeddings = None
            logger.warning("AIæ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
        
        # æœ€é©åŒ–ã•ã‚ŒãŸæ„å›³æŠ½å‡ºå™¨
        self.intent_extractor = OptimizedUserIntentExtractor(self.llm, self.optimizer)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼ˆè»½é‡ç‰ˆï¼‰
        self.vector_store = None
        self.hybrid_engine = None
        
        # åˆæœŸåŒ–
        self._initialize_optimized_components()
    
    def _initialize_optimized_components(self):
        """æœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½¿ç”¨ï¼‰"""
        try:
            # ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å–å¾—
            self.vector_store = VectorStoreManager.get_vector_store()
            
            if self.vector_store:
                logger.info("âœ… æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å–å¾—å®Œäº†ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰")
                
                # æœ€é©åŒ–ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³
                self.hybrid_engine = HybridSearchEngine(
                    meilisearch_service=self.meilisearch_service,
                    vector_store=self.vector_store
                )
                # æ¤œç´¢é‡ã¿ã‚’é«˜é€ŸåŒ–å‘ã‘ã«èª¿æ•´
                self.hybrid_engine.search_weights = {
                    "semantic_weight": 0.7,  # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é‡è¦–
                    "structured_weight": 0.3,
                    "intent_boost": 0.15
                }
                logger.info("âœ… æœ€é©åŒ–ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
            else:
                logger.warning("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆAIæ©Ÿèƒ½åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ï¼‰")
                self.hybrid_engine = None
            
        except Exception as e:
            logger.error(f"æœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.vector_store = None
            self.hybrid_engine = None
    
    async def get_fast_recommendation(
        self,
        user_input: str,
        chat_history: List[Dict[str, str]] = None,
        limit: int = 3,  # æ¨è–¦æ•°ã‚’å‰Šæ¸›
        structured_intent: Dict[str, Any] = None  # æ§‹é€ åŒ–æ„å›³ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    ) -> Dict[str, Any]:
        """
        Phase 3: é«˜é€Ÿæ¨è–¦ãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        ç›®æ¨™: 3-5ç§’ä»¥å†…ã§ã®å¿œç­”
        """
        start_time = datetime.now()
        processing_steps = []
        
        try:
            logger.info("Phase 3: é«˜é€Ÿæ¨è–¦é–‹å§‹")
            
            # æ§‹é€ åŒ–æ„å›³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            if structured_intent:
                logger.info(f"ğŸ“ æ§‹é€ åŒ–æ„å›³ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨: {structured_intent}")
                user_intent = self.intent_extractor._normalize_intent(structured_intent)
                processing_steps.append("æ§‹é€ åŒ–æ„å›³ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
            else:
                # Step 1: æ„å›³æŠ½å‡ºï¼ˆé«˜é€Ÿä¸¦åˆ—å®Ÿè¡Œï¼‰
                intent_start = time.time()
                user_intent = await self.intent_extractor.extract_intent(user_input)
                intent_time = time.time() - intent_start
                processing_steps.append(f"é«˜é€Ÿæ„å›³æŠ½å‡º: {intent_time:.2f}s")

            # Step 2: ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢åˆæœŸåŒ–ã¨æ¤œç´¢ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            if self.hybrid_engine:
                search_start = time.time()
                
                # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢åˆæœŸåŒ–ã¨æ¤œç´¢æº–å‚™ã‚’ä¸¦åˆ—å®Ÿè¡Œ
                init_task = asyncio.create_task(self._ensure_vector_store_ready())
                search_prep_task = asyncio.create_task(self._prepare_search_params(user_intent))
                
                # åˆæœŸåŒ–å®Œäº†å¾Œã€æ¤œç´¢å®Ÿè¡Œ
                await asyncio.gather(init_task, search_prep_task)
                
                # æ¤œç´¢å®Ÿè¡Œ
                hybrid_results, search_metadata = await self._fast_hybrid_search(
                    query=user_input,
                    user_intent=user_intent,
                    limit=limit
                )
                search_time = time.time() - search_start
                processing_steps.append(f"ä¸¦åˆ—ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢: {search_time:.2f}s")
            if self.hybrid_engine:
                search_start = time.time()
                
                
                # äºˆç®—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å¼·åˆ¶é©ç”¨ï¼ˆäº‹å¾Œå‡¦ç†ï¼‰
                if user_intent.get('budget_min') or user_intent.get('budget_max'):
                    hybrid_results = self._apply_budget_filter(hybrid_results, user_intent)
                    processing_steps.append(f"äºˆç®—ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {len(hybrid_results)}ä»¶")
                
                # Step 3: AIå¿œç­”ç”Ÿæˆï¼ˆä¸¦åˆ—åŒ–ã®æº–å‚™ï¼‰
                response_start = time.time()
                
                # AIå¿œç­”ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ã‚’ä¸¦åˆ—å®Ÿè¡Œ
                response_task = asyncio.create_task(self._generate_fast_response(
                    user_input=user_input,
                    user_intent=user_intent,
                    recommended_products=hybrid_results
                ))
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ï¼ˆä¸¦åˆ—ã§å®Ÿè¡Œå¯èƒ½ãªéƒ¨åˆ†ï¼‰
                metadata_task = asyncio.create_task(self._build_response_metadata(
                    start_time, search_time, user_intent, search_metadata, processing_steps
                ))
                
                # ä¸¡æ–¹ã®å®Œäº†ã‚’å¾…ã¤
                ai_response, base_metadata = await asyncio.gather(response_task, metadata_task)
                
                response_time = time.time() - response_start
                processing_steps.append(f"é«˜é€Ÿå¿œç­”ç”Ÿæˆ: {response_time:.2f}s")
                
                # æœ€çµ‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
                base_metadata["performance"]["response_time_ms"] = response_time * 1000
                
                return {
                    "ai_response": ai_response,
                    "recommendations": hybrid_results,
                    "user_intent": user_intent,
                    "intent_analysis": user_intent,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›æ€§ã®ãŸã‚
                    **base_metadata
                }
            
            else:
                # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return await self._emergency_response(user_input)
                
        except Exception as e:
            logger.error(f"é«˜é€Ÿæ¨è–¦ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return await self._emergency_response(user_input)
    
    async def _build_response_metadata(self, start_time: datetime, search_time: float, 
                                       user_intent: Dict, search_metadata: Dict, 
                                       processing_steps: List[str]) -> Dict:
        """
        ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å‡¦ç†ç”¨ã«æ§‹ç¯‰
        """
        total_time = (datetime.now() - start_time).total_seconds()
        
        return {
            "search_metadata": search_metadata,
            "processing_steps": processing_steps,
            "performance": {
                "total_time_ms": total_time * 1000,
                "search_time_ms": search_time * 1000,
                "optimization": "phase3_fast"
            }
        }
    
    async def _ensure_vector_store_ready(self):
        """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®æº–å‚™ã‚’ç¢ºå®Ÿã«å®Ÿè¡Œ"""
        try:
            if not hasattr(self, '_vector_store_ready'):
                # VectorStoreManagerã‚’ä½¿ç”¨ã—ã¦åŠ¹ç‡çš„ã«åˆæœŸåŒ–
                vector_store = VectorStoreManager.get_vector_store()
                self._vector_store_ready = True
                logger.info("ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.warning(f"ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢åˆæœŸåŒ–è­¦å‘Š: {e}")
    
    async def _prepare_search_params(self, user_intent: Dict) -> Dict:
        """æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äº‹å‰æº–å‚™"""
        return {
            "semantic_threshold": 0.6,
            "budget_filter": user_intent.get('budget_min') or user_intent.get('budget_max'),
            "category_preference": user_intent.get('category'),
            "target_relationship": user_intent.get('target_relationship')
        }
    
    async def _fast_hybrid_search(
        self,
        query: str,
        user_intent: Dict[str, Any],
        limit: int
    ) -> Tuple[List[GiftItem], Dict[str, Any]]:
        """æœ€é©åŒ–ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢"""
        try:
            # æ¤œç´¢ç¯„å›²ã‚’åˆ¶é™ï¼ˆé«˜é€ŸåŒ–ï¼‰
            limited_limit = min(limit * 2, 6)  # æœ€å¤§6ä»¶ã¾ã§
            
            results, metadata = await self.hybrid_engine.hybrid_search(
                query=query,
                user_intent=user_intent,
                limit=limited_limit,
                semantic_threshold=0.6  # é–¾å€¤ã‚’ä¸‹ã’ã¦é«˜é€ŸåŒ–
            )
            
            # RRFçµæœã‹ã‚‰GiftItemã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡º
            gift_items = []
            for result in results[:limit]:
                if isinstance(result, dict) and 'product' in result:
                    # RRFçµ±åˆçµæœã®å ´åˆ
                    gift_items.append(result['product'])
                elif hasattr(result, 'id'):
                    # æ—¢ã«GiftItemã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                    gift_items.append(result)
                else:
                    logger.warning(f"ä¸æ˜ãªçµæœå½¢å¼: {type(result)}")
            
            logger.info(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœ: {len(results)}ä»¶ â†’ {len(gift_items)}ä»¶ã®GiftItemå¤‰æ›")
            return gift_items, metadata
            
        except Exception as e:
            logger.error(f"é«˜é€Ÿãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            logger.error(f"ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
            return [], {"error": str(e), "fallback": True}
    
    async def _generate_fast_response(
        self,
        user_input: str,
        user_intent: Dict[str, Any],
        recommended_products: List[GiftItem]
    ) -> str:
        """é«˜é€ŸAIå¿œç­”ç”Ÿæˆï¼ˆç°¡æ½”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‰ˆï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        response_key = self.optimizer.get_cache_key(
            f"response_{user_input}_{len(recommended_products)}"
        )
        cached_response = self.optimizer.get_cached(response_key)
        
        if cached_response:
            logger.info("AIå¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ")
            return cached_response
        
        try:
            # ç°¡æ½”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if recommended_products:
                products_text = "\n".join([
                    f"{i+1}. {p.title} - {p.price:,}å††"
                    for i, p in enumerate(recommended_products[:3])
                ])
            else:
                products_text = "è©²å½“ã™ã‚‹å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            fast_prompt = f"""
å†…ç¥ã„ã‚®ãƒ•ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã¨ã—ã¦ã€ç°¡æ½”ã«æ¨è–¦ã—ã¦ãã ã•ã„ã€‚

è¦æœ›: {user_input}

æ¨è–¦å•†å“:
{products_text}

ç”¨é€”: {user_intent.get('occasion', 'ä¸æ˜')}
ç›¸æ‰‹: {user_intent.get('target_relationship', 'ä¸æ˜')}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰:
1. æ¨è–¦ç†ç”±
2. ãŠã™ã™ã‚å•†å“ï¼ˆä¸Šä½2ã¤ï¼‰
3. ä¸€è¨€ã‚¢ãƒ‰ãƒã‚¤ã‚¹
"""
            
            response = await self.llm.ainvoke(fast_prompt)
            result = response.content
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.optimizer.set_cached(response_key, result)
            
            return result
            
        except Exception as e:
            logger.error(f"é«˜é€Ÿå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._get_emergency_text(user_input, recommended_products)
    
    async def _fallback_fast_search(
        self,
        user_input: str,
        user_intent: Dict[str, Any],
        limit: int
    ) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é«˜é€Ÿæ¤œç´¢"""
        try:
            # æ§‹é€ åŒ–æ¤œç´¢ã®ã¿ã§é«˜é€ŸåŒ–
            search_params = SearchParams(
                q=user_input,
                occasion=user_intent.get('occasion') if user_intent.get('occasion') != 'unknown' else None,
                price_min=user_intent.get('budget_min'),
                price_max=user_intent.get('budget_max'),
                limit=limit
            )
            
            search_result = self.meilisearch_service.search_items(search_params)
            
            # ç°¡å˜ãªå¿œç­”ç”Ÿæˆ
            simple_response = f"ã€Œ{user_input}ã€ã«å¯¾ã—ã¦{len(search_result.hits)}ä»¶ã®å•†å“ã‚’ã”ææ¡ˆã„ãŸã—ã¾ã™ã€‚"
            
            return {
                "ai_response": simple_response,
                "recommendations": search_result.hits,
                "user_intent": user_intent,
                "search_metadata": {"strategy": "fallback_structured_only"},
                "processing_steps": ["ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ§‹é€ åŒ–æ¤œç´¢"],
                "reasoning": "é«˜é€Ÿãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢"
            }
            
        except Exception as e:
            logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return await self._emergency_response(user_input)
    
    async def _emergency_response(self, user_input: str) -> Dict[str, Any]:
        """ç·Šæ€¥æ™‚ã®æœ€å°å¿œç­”"""
        return {
            "ai_response": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã€Œ{user_input}ã€ã«ã¤ã„ã¦ã®ã”è¦æœ›ã‚’æ‰¿ã‚Šã¾ã—ãŸã€‚å°‘ã€…ãŠæ™‚é–“ã‚’ã„ãŸã ã„ã¦ã€æœ€é©ãªå•†å“ã‚’ãŠæ¢ã—ã„ãŸã—ã¾ã™ã€‚",
            "recommendations": [],
            "user_intent": {"occasion": "unknown"},
            "search_metadata": {"strategy": "emergency"},
            "processing_steps": ["ç·Šæ€¥å¿œç­”"],
            "reasoning": "ç·Šæ€¥æ™‚æœ€å°å¿œç­”"
        }
    
    def _get_emergency_text(self, user_input: str, products: List[GiftItem]) -> str:
        """ç·Šæ€¥æ™‚ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        if products:
            return f"ã€Œ{user_input}ã€ã®ã”è¦æœ›ã«ãŠå¿œãˆã—ã¦ã€{len(products)}ä»¶ã®å•†å“ã‚’ã”ææ¡ˆã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã”æ¤œè¨ãã ã•ã„ã€‚"
        else:
            return f"ã€Œ{user_input}ã€ã«åˆã†å•†å“ã‚’ãŠæ¢ã—ã—ã¦ãŠã‚Šã¾ã™ã€‚åˆ¥ã®æ¡ä»¶ã§ã‚‚ãŠæ°—è»½ã«ãŠå£°ãŒã‘ãã ã•ã„ã€‚"
    
    def _apply_budget_filter(self, items: List[GiftItem], user_intent: Dict[str, Any]) -> List[GiftItem]:
        """
        äºˆç®—ç¯„å›²ã§å•†å“ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆäº‹å¾Œå‡¦ç†ï¼‰
        """
        budget_min = user_intent.get('budget_min')
        budget_max = user_intent.get('budget_max')
        
        if not budget_min and not budget_max:
            return items
        
        filtered_items = []
        for item in items:
            price = item.price
            
            # äºˆç®—ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if budget_min and price < budget_min:
                continue
            if budget_max and price > budget_max:
                continue
                
            filtered_items.append(item)
        
        logger.info(f"ğŸ’° äºˆç®—ãƒ•ã‚£ãƒ«ã‚¿: {len(items)}ä»¶ â†’ {len(filtered_items)}ä»¶ (ç¯„å›²: {budget_min}ã€œ{budget_max}å††)")
        return filtered_items
    
    async def health_check(self) -> Dict[str, Any]:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
        return {
            "status": "healthy",
            "optimization": "phase3",
            "cache_size": len(self.optimizer.cache),
            "hybrid_engine_ready": self.hybrid_engine is not None,
            "vector_store_ready": self.vector_store is not None
        }